## Sample Testing 的整体流程

Sample testing 是针对链路预测任务的排名评估模式，主要用于计算 MRR（Mean Reciprocal Rank）、Hits@1、Hits@5 和 Hits@10 等指标。它不同于全量测试（all mode），而是通过采样负样本来近似评估模型在测试集上的排名性能。

### 1. **模式选择与参数**
- 在 test_ranking.py 中，通过 `--mode sample` 参数启用采样测试（默认模式）。
- 关键参数：
  - `--num_samples`：每个测试链接的负样本数量，默认 50（实验中使用的值）。
  - `--hop`：子图提取的跳数，默认 3，但在最佳实验中设置为 2。
  - `--sequential`：是否使用顺序处理（避免内存爆炸，默认 False，使用多进程）。

### 2. **负样本生成**
对于每个测试三元组 `(head, rel, tail)`：
- **替换尾实体（Tail Corruption）**：
  - 固定 `head` 和 `rel`，随机选择新的 `tail`，但确保 `(head, rel, new_tail)` 不在训练图中（即不存在的边）。
  - 生成 `num_samples`（50）个这样的负样本。
  - 正样本 `(head, rel, tail)` 作为第一个候选。
  - 总共 51 个候选（1 正 + 50 负）。
- **替换头实体（Head Corruption）**：
  - 固定 `tail` 和 `rel`，随机选择新的 `head`，生成 50 个负样本。
  - 正样本作为第一个候选。
  - 总共 51 个候选。
- 每个测试三元组生成 102 个候选（head 方向 51 + tail 方向 51），但正样本在两个方向中都出现。

负样本生成函数：`get_neg_samples_replacing_head_tail()`，它通过循环尝试随机采样，直到找到不存在的边为止（最多尝试 `num_samples * 20` 次）。

### 3. **子图提取**
- 对于每个候选三元组，提取 `hop`-hop 子图（实验中使用 hop=2）。
- 子图包括目标边及其邻域节点，使用 BFS 提取。
- 子图经过标签编码（DRNL：Double-Radius Node Labeling），为节点分配距离根节点的标签。
- 如果使用 KGE 嵌入（`--use_kge_embeddings`），会加载预训练的实体嵌入作为节点特征。

### 4. **模型评分**
- 使用训练好的 GraIL 模型对每个子图计算分数（预测该三元组存在的概率）。
- 模型输入：批处理的 DGL 图 + 关系标签。
- 分数表示为实数，越高表示越可能存在。

### 5. **排名计算**
- 对于 head 方向的 51 个候选：
  - 根据模型分数从高到低排序。
  - 找到正样本 `(head, rel, tail)` 在排序中的位置（排名，从 1 开始）。
- 同样计算 tail 方向的排名。
- 每个测试三元组产生两个排名（head 和 tail）。

### 6. **指标计算**
- **MRR**：所有排名的倒数平均值（`np.mean(1 / np.array(ranks))`）。
- **Hits@K**：排名 ≤ K 的比例（K=1,5,10）。
- 实验结果示例（exp_v3_hop2_stable）：
  - MRR: 0.295
  - Hits@1: 0.219
  - Hits@5: 0.338
  - Hits@10: 0.413

### 7. **处理与优化**
- **并行处理**：默认使用多进程（`mp.Pool`），`num_workers` 参数控制进程数。
- **顺序处理**：当 `mode='all'` 或指定 `--sequential` 时，使用单进程顺序处理，避免在 WSL 或内存有限环境下崩溃（all mode 会生成 ~816K 子图，导致内存爆炸）。
- **输出**：保存预测分数到文件（如 `grail_ranking_head_predictions.txt`），用于进一步分析。

## 与其他测试模式的区别
- **Sample Mode**：采样 50 个负样本/链接，快速但近似。
- **All Mode**：对所有实体进行排名（替换为所有可能的实体），精确但计算量巨大（测试集 80 三元组 × 5104 实体 × 2 方向 ≈ 816K 子图）。
- **AUC 测试**（test_auc.py）：使用固定负样本（默认 1 个/链接），计算 AUC 和 AUC-PR，基于二分类评估。

---

## 一致性分析

### 1. **测试逻辑的核心**
- **链路预测任务**：测试脚本（test_ranking.py）评估模型预测三元组 `(head, relation, tail)` 是否存在的排名能力。
- **采样模式**：对于每个测试三元组，生成负样本（替换 head 或 tail），然后用模型评分并计算排名指标（MRR, Hits@K）。
- **归纳式设置**：根据 experiment_summary.md，MDKG_v1 数据集是**归纳式的**（inductive），训练和测试实体完全不同。这意味着模型从未见过测试集中的疾病实体，只能通过子图结构和关系模式来预测。

### 2. **与你的目标匹配**
你的目标：**预测新疾病（模型未见过的 disease）与药物的 `treatment_for` 链接**，即找出潜在治疗该疾病的药物。

- **测试数据确认**：
  - 测试集（test.txt）包含 **80 个 `treatment_for` 三元组**，格式为 `drug treatment_for disease`（例如：`drug::olanzapine treatment_for disease::schizophrenia`）。
  - 训练集（train.txt）包含 **938 个 `treatment_for` 三元组**，模型在训练时学习了这种关系的模式。
  - 测试集中的疾病实体是模型未见过的（归纳式），所以测试正是评估模型对新疾病预测治疗药物的能力。

- **测试过程对应**：
  - 对于测试三元组如 `(drug::olanzapine, treatment_for, disease::schizophrenia)`：
    - 生成负样本：替换 drug（e.g., `(drug::haloperidol, treatment_for, disease::schizophrenia)`）或替换 disease（e.g., `(drug::olanzapine, treatment_for, disease::depression)`），但确保负样本不在训练图中。
    - 模型对正样本和负样本评分，计算正样本的排名（越低越好，表示模型正确预测了这个链接）。
  - 这直接模拟了你的场景：给定一个新疾病，模型需要从所有可能药物中排名哪些有 `treatment_for` 关系。

### 3. **为什么是归纳式预测**
- **实体未见过**：训练和测试实体不同（从 experiment_summary.md 确认：5104 训练实体 vs. 测试实体），所以测试评估的是模型对新疾病的泛化能力。
- **子图-based 方法**：GraIL 使用局部子图（hop=2），不依赖全局实体嵌入，能处理新实体。
- **指标意义**：
  - **Hits@10 = 0.413**：意味着对于新疾病，模型能在前10个候选药物中找到正确治疗药物的概率为 41.3%。
  - 这正是你需要的：为新疾病推荐潜在药物列表。

### 4. **潜在差异或注意点**
- **方向**：测试中三元组是 `drug treatment_for disease`，但你的描述是“disease 和 drug 的 treatment_for link”。关系是无向的（在图中），但测试评估的是预测存在的链接，无论方向。
- **负样本生成**：采样 50 个负样本/方向，近似全量排名。如果需要更精确，可以用 `all` 模式（但耗时长，~80分钟）。
- **如果不完全匹配**：如果你的目标是纯预测（而非排名评估），可能需要修改脚本输出预测分数，而不是排名。但当前逻辑已经覆盖了核心需求。

## 总结
是的，测试逻辑与你的目标一致：它评估模型预测新疾病与药物的 `treatment_for` 关系的排名能力，适用于归纳式场景。实验结果显示模型在 Hit@10 上达到 0.413，表明它能有效识别潜在治疗药物。

如果你想运行测试或调整逻辑（e.g., 聚焦特定疾病），我可以帮你准备命令！